{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16e37431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_confusion_matrix, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import math \n",
    "\n",
    "df = pd.read_csv('./X_train.csv', error_bad_lines=False, sep=',')\n",
    "#df = df.drop(df.columns[[0, 1]], axis = 1)\n",
    "prdct = df['MQT1_category']\n",
    "y_train = prdct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbad66ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    106\n",
       "4.0     48\n",
       "5.0     37\n",
       "1.0     30\n",
       "2.0     21\n",
       "Name: MQT1_category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = pd.read_csv('./X_test.csv', error_bad_lines=False, sep = ',')\n",
    "dft['MQT1_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5fcd262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((242, 129), (242,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prdct_t = dft['MQT1_category']\n",
    "y_test = prdct_t\n",
    "dft.drop('MQT1_category', axis = 1, inplace = True)\n",
    "X_test = dft\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "956a3bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MQT1_category                   1.000000\n",
       "veel_leeftijdsgenoten           0.159286\n",
       "sportmogelijkheden_buurt        0.152230\n",
       "postcode_cijfers                0.145996\n",
       "Respondentnummer                0.140750\n",
       "                                  ...   \n",
       "8. Bal schoppen                 0.003242\n",
       "cult_achtergrond_partner        0.001096\n",
       "fietsen_zonder_zijwielen_mnd    0.000970\n",
       "zelf_kruipen_mnd                0.000779\n",
       "Lengte (in m)                        NaN\n",
       "Name: MQT1_category, Length: 130, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlationMQ1 = df.corr()['MQT1_category'].abs().sort_values(ascending = False)\n",
    "correlationMQ1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47fef4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondentnummer</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Geboortedatum</th>\n",
       "      <th>Age on testday (t0)</th>\n",
       "      <th>Lengte (afgerond op 0.1 cm)</th>\n",
       "      <th>Gewicht (afgerond op 0.1 kg)</th>\n",
       "      <th>Lengte (in m)</th>\n",
       "      <th>Gymles</th>\n",
       "      <th>Zwemles J/N</th>\n",
       "      <th>Zwemles</th>\n",
       "      <th>...</th>\n",
       "      <th>belonen_wanneer_rustig</th>\n",
       "      <th>buitenspeel_materiaal_beschikbaar</th>\n",
       "      <th>tv_bezighouden</th>\n",
       "      <th>niet_buiten_verkeersveiligheid</th>\n",
       "      <th>niet_buiten_criminaliteit</th>\n",
       "      <th>toestaan_langetijd_schermen</th>\n",
       "      <th>Zip-code school</th>\n",
       "      <th>MQT0_category</th>\n",
       "      <th>BMI_category</th>\n",
       "      <th>Age differents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960157</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025735</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045956</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.980116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.980270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.970199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.759191</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.955445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1571</th>\n",
       "      <td>0.995362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104779</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0.995138</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.619485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>0.497472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.331176</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>0.522442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.007551</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1575 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Respondentnummer  Gender  Geboortedatum  Age on testday (t0)  \\\n",
       "0             0.960157     0.0       0.025735             0.666667   \n",
       "1             0.985381     0.0       0.045956             0.666667   \n",
       "2             0.980116     1.0       0.625000             0.333333   \n",
       "3             0.980270     1.0       0.544118             0.333333   \n",
       "4             0.970199     0.0       0.759191             0.666667   \n",
       "...                ...     ...            ...                  ...   \n",
       "1570          0.955445     0.0       0.262868             0.666667   \n",
       "1571          0.995362     1.0       0.104779             0.666667   \n",
       "1572          0.995138     1.0       0.619485             0.000000   \n",
       "1573          0.497472     1.0       0.551471             1.000000   \n",
       "1574          0.522442     0.0       0.808824             0.666667   \n",
       "\n",
       "      Lengte (afgerond op 0.1 cm)  Gewicht (afgerond op 0.1 kg)  \\\n",
       "0                        0.473684                      0.380952   \n",
       "1                        0.421053                      0.285714   \n",
       "2                        0.500000                      0.476190   \n",
       "3                        0.394737                      0.285714   \n",
       "4                        0.578947                      0.380952   \n",
       "...                           ...                           ...   \n",
       "1570                     0.736842                      0.571429   \n",
       "1571                     0.368421                      0.238095   \n",
       "1572                     0.210526                      0.190476   \n",
       "1573                     0.552632                      0.523810   \n",
       "1574                     0.736842                      0.523810   \n",
       "\n",
       "      Lengte (in m)  Gymles  Zwemles J/N  Zwemles  ...  \\\n",
       "0               0.0    0.75          0.0     1.00  ...   \n",
       "1               0.0    0.75          0.0     0.50  ...   \n",
       "2               0.0    1.00          1.0     1.00  ...   \n",
       "3               0.0    1.00          1.0     1.00  ...   \n",
       "4               0.0    1.00          0.0     0.75  ...   \n",
       "...             ...     ...          ...      ...  ...   \n",
       "1570            0.0    1.00          0.0     1.00  ...   \n",
       "1571            0.0    1.00          0.0     1.00  ...   \n",
       "1572            0.0    1.00          1.0     1.00  ...   \n",
       "1573            0.0    0.75          0.0     0.50  ...   \n",
       "1574            0.0    0.00          0.0     1.00  ...   \n",
       "\n",
       "      belonen_wanneer_rustig  buitenspeel_materiaal_beschikbaar  \\\n",
       "0                       0.50                                1.0   \n",
       "1                       0.25                                1.0   \n",
       "2                       0.50                                1.0   \n",
       "3                       0.25                                1.0   \n",
       "4                       0.00                                1.0   \n",
       "...                      ...                                ...   \n",
       "1570                    0.50                                1.0   \n",
       "1571                    0.25                                1.0   \n",
       "1572                    0.00                                1.0   \n",
       "1573                    0.75                                1.0   \n",
       "1574                    0.50                                1.0   \n",
       "\n",
       "      tv_bezighouden  niet_buiten_verkeersveiligheid  \\\n",
       "0               0.50                            0.25   \n",
       "1               0.50                            0.00   \n",
       "2               0.25                            0.00   \n",
       "3               0.50                            0.00   \n",
       "4               0.50                            0.00   \n",
       "...              ...                             ...   \n",
       "1570            0.00                            0.00   \n",
       "1571            0.25                            0.00   \n",
       "1572            1.00                            1.00   \n",
       "1573            0.75                            0.25   \n",
       "1574            0.50                            0.00   \n",
       "\n",
       "      niet_buiten_criminaliteit  toestaan_langetijd_schermen  Zip-code school  \\\n",
       "0                          0.50                         0.50         0.348436   \n",
       "1                          0.00                         0.50         0.348436   \n",
       "2                          0.00                         0.50         0.348436   \n",
       "3                          0.00                         0.50         0.348436   \n",
       "4                          0.00                         0.25         0.348436   \n",
       "...                         ...                          ...              ...   \n",
       "1570                       0.00                         0.25         0.348436   \n",
       "1571                       0.00                         0.50         0.348436   \n",
       "1572                       1.00                         0.75         0.348436   \n",
       "1573                       0.25                         0.75         0.331176   \n",
       "1574                       0.00                         0.50         0.007551   \n",
       "\n",
       "      MQT0_category  BMI_category  Age differents  \n",
       "0              0.25           0.0             0.0  \n",
       "1              0.50           0.0             0.5  \n",
       "2              1.00           0.0             0.5  \n",
       "3              0.25           0.0             0.0  \n",
       "4              0.75           0.0             0.5  \n",
       "...             ...           ...             ...  \n",
       "1570           0.75           0.0             0.0  \n",
       "1571           0.50           0.0             0.5  \n",
       "1572           0.50           0.0             0.0  \n",
       "1573           0.25           0.5             0.5  \n",
       "1574           0.50           0.0             0.5  \n",
       "\n",
       "[1575 rows x 129 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('MQT1_category', axis = 1, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a81398be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1575, 129), (1575,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b51dad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training score: 0.9917460317460317\n",
      " testing score: 0.39669421487603307\n",
      "Accuracy Score of Random Forest is : 0.39669421487603307\n",
      "Confusion Matrix : \n",
      "[[10  1 14  3  2]\n",
      " [ 4  0 16  0  1]\n",
      " [ 9  3 77  9  8]\n",
      " [ 5  1 33  4  5]\n",
      " [ 2  0 23  7  5]]\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.33      0.33      0.33        30\n",
      "         2.0       0.00      0.00      0.00        21\n",
      "         3.0       0.47      0.73      0.57       106\n",
      "         4.0       0.17      0.08      0.11        48\n",
      "         5.0       0.24      0.14      0.17        37\n",
      "\n",
      "    accuracy                           0.40       242\n",
      "   macro avg       0.24      0.26      0.24       242\n",
      "weighted avg       0.32      0.40      0.34       242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the model classifier to fit data:\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_leaf=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict y data with classifier: \n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "model.score(X_test, y_test)\n",
    "\n",
    "print(' training score: {}'.format(model.score(X_train, y_train)))\n",
    "print(' testing score: {}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "acc_rd_clf = accuracy_score(y_test, y_predict)\n",
    "conf = confusion_matrix(y_test, y_predict)\n",
    "clf_report = classification_report(y_test, y_predict)\n",
    "\n",
    "print(f\"Accuracy Score of Random Forest is : {acc_rd_clf}\")\n",
    "print(f\"Confusion Matrix : \\n{conf}\")\n",
    "print(f\"Classification Report : \\n{clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "337653c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95b4a4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondentnummer</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Geboortedatum</th>\n",
       "      <th>Age on testday (t0)</th>\n",
       "      <th>Lengte (afgerond op 0.1 cm)</th>\n",
       "      <th>Gewicht (afgerond op 0.1 kg)</th>\n",
       "      <th>Lengte (in m)</th>\n",
       "      <th>Gymles</th>\n",
       "      <th>Zwemles J/N</th>\n",
       "      <th>Zwemles</th>\n",
       "      <th>...</th>\n",
       "      <th>buitenspeel_materiaal_beschikbaar</th>\n",
       "      <th>tv_bezighouden</th>\n",
       "      <th>niet_buiten_verkeersveiligheid</th>\n",
       "      <th>niet_buiten_criminaliteit</th>\n",
       "      <th>toestaan_langetijd_schermen</th>\n",
       "      <th>Zip-code school</th>\n",
       "      <th>MQT0_category</th>\n",
       "      <th>BMI_category</th>\n",
       "      <th>Age differents</th>\n",
       "      <th>Predicted_MQT1_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325368</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.994969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.738971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.457714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.444853</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.961165</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071691</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.547451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.341912</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.282632</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.995357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.509191</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.970174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.301471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.527383</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.689338</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>0.955236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663603</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.995079</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.373162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.348436</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Respondentnummer  Gender  Geboortedatum  Age on testday (t0)  \\\n",
       "0            0.985241     0.0       0.325368             0.666667   \n",
       "1            0.994969     0.0       0.738971             0.000000   \n",
       "2            0.457714     0.0       0.444853             0.666667   \n",
       "3            0.970134     0.0       0.071691             0.666667   \n",
       "4            0.547451     1.0       0.341912             0.666667   \n",
       "..                ...     ...            ...                  ...   \n",
       "237          0.995357     1.0       0.509191             0.333333   \n",
       "238          0.970174     1.0       0.301471             0.000000   \n",
       "239          0.527383     1.0       0.689338             0.666667   \n",
       "240          0.955236     0.0       0.663603             0.666667   \n",
       "241          0.995079     1.0       0.373162             0.000000   \n",
       "\n",
       "     Lengte (afgerond op 0.1 cm)  Gewicht (afgerond op 0.1 kg)  Lengte (in m)  \\\n",
       "0                       0.736842                      0.523810            0.0   \n",
       "1                       0.342105                      0.190476            0.0   \n",
       "2                       0.500000                      0.428571            0.0   \n",
       "3                       0.578947                      0.285714            0.0   \n",
       "4                       0.605263                      0.333333            0.0   \n",
       "..                           ...                           ...            ...   \n",
       "237                     0.421053                      0.333333            0.0   \n",
       "238                     0.315789                      0.142857            0.0   \n",
       "239                     0.526316                      0.333333            0.0   \n",
       "240                     0.500000                      0.285714            0.0   \n",
       "241                     0.394737                      0.571429            0.0   \n",
       "\n",
       "     Gymles  Zwemles J/N  Zwemles  ...  buitenspeel_materiaal_beschikbaar  \\\n",
       "0      1.00          0.0     0.75  ...                               0.75   \n",
       "1      1.00          0.0     0.00  ...                               1.00   \n",
       "2      1.00          0.0     0.50  ...                               0.75   \n",
       "3      1.00          0.0     0.75  ...                               0.75   \n",
       "4      1.00          1.0     1.00  ...                               0.75   \n",
       "..      ...          ...      ...  ...                                ...   \n",
       "237    1.00          0.0     0.50  ...                               1.00   \n",
       "238    1.00          0.0     1.00  ...                               1.00   \n",
       "239    1.00          0.0     1.00  ...                               0.75   \n",
       "240    1.00          0.0     1.00  ...                               1.00   \n",
       "241    0.75          0.0     0.75  ...                               0.75   \n",
       "\n",
       "     tv_bezighouden  niet_buiten_verkeersveiligheid  \\\n",
       "0              0.50                            0.00   \n",
       "1              0.50                            0.50   \n",
       "2              0.50                            0.25   \n",
       "3              0.50                            0.25   \n",
       "4              0.25                            0.25   \n",
       "..              ...                             ...   \n",
       "237            0.25                            0.50   \n",
       "238            0.00                            0.50   \n",
       "239            0.25                            0.75   \n",
       "240            0.50                            0.00   \n",
       "241            0.50                            0.00   \n",
       "\n",
       "     niet_buiten_criminaliteit  toestaan_langetijd_schermen  Zip-code school  \\\n",
       "0                         0.00                         0.50         0.348436   \n",
       "1                         0.00                         0.50         0.348436   \n",
       "2                         0.00                         0.25         0.961165   \n",
       "3                         0.00                         0.25         0.348436   \n",
       "4                         0.25                         0.25         0.282632   \n",
       "..                         ...                          ...              ...   \n",
       "237                       0.25                         0.25         0.348436   \n",
       "238                       0.50                         0.00         0.348436   \n",
       "239                       0.25                         0.00         0.000000   \n",
       "240                       0.00                         0.25         0.348436   \n",
       "241                       0.00                         0.50         0.348436   \n",
       "\n",
       "     MQT0_category  BMI_category  Age differents  Predicted_MQT1_category  \n",
       "0             1.00           0.0             0.5                      3.0  \n",
       "1             0.50           0.0             0.0                      2.0  \n",
       "2             0.25           0.0             0.5                      3.0  \n",
       "3             0.50           0.0             0.5                      3.0  \n",
       "4             1.00           0.0             0.5                      4.0  \n",
       "..             ...           ...             ...                      ...  \n",
       "237           0.50           0.0             0.0                      1.0  \n",
       "238           0.50           0.0             0.0                      3.0  \n",
       "239           0.25           0.0             0.5                      3.0  \n",
       "240           0.50           0.0             0.5                      4.0  \n",
       "241           0.50           1.0             0.5                      3.0  \n",
       "\n",
       "[242 rows x 130 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Predicted_MQT1_category'] = y_predict\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d45e7d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predicted_MQT1_category     1.000000e+00\n",
       "postcode_cijfers            3.073343e-01\n",
       "Respondentnummer            2.913216e-01\n",
       "drukte_buurt                2.361650e-01\n",
       "Age on testday (t0)         1.926502e-01\n",
       "                                ...     \n",
       "invul_vragenlijst           6.258325e-17\n",
       "niet_actief_speelplekken    2.446960e-17\n",
       "aantal_dagen_zwemles        1.053291e-17\n",
       "lid_sportvereniging         2.818791e-18\n",
       "Lengte (in m)                        NaN\n",
       "Name: Predicted_MQT1_category, Length: 130, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMQT1_predicted = X_test.corr()['Predicted_MQT1_category'].abs().sort_values(ascending = False)\n",
    "CMQT1_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "837746e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n"
     ]
    }
   ],
   "source": [
    "print(RandomForestClassifier._estimator_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4aaf9204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130\n",
      "129\n",
      "242\n",
      "1575\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test.columns))\n",
    "print(len(X_train.columns))\n",
    "print(len(X_test.index))\n",
    "print(len(X_train.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ac10fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:771: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 762, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 216, in __call__\n",
      "    return self._score(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 264, in _score\n",
      "    return self._sign * self._score_func(y_true, y_pred, **self._kwargs)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1872, in recall_score\n",
      "    _, r, _, _ = precision_recall_fscore_support(\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1534, in precision_recall_fscore_support\n",
      "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
      "  File \"/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/metrics/_classification.py\", line 1355, in _check_set_wise_labels\n",
      "    raise ValueError(\n",
      "ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/jupyterhub/anaconda/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.9917460317460317\n",
      " testing score: 0.39669421487603307\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "X_train = pd.read_csv('X_train.csv', error_bad_lines=False, sep=',')\n",
    "y_train = X_train['MQT1_category']\n",
    "X_train.drop('MQT1_category', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "X_test = pd.read_csv('X_test.csv', error_bad_lines=False, sep = ',')\n",
    "y_test = X_test['MQT1_category']\n",
    "X_test.drop('MQT1_category', axis = 1, inplace = True)\n",
    "\n",
    "# clf = RandomForestClassifier()\n",
    "# clf.fit(X_train, y_train)\n",
    "grid_values = {'n_estimators': [50]}\n",
    "grid_clf_acc = GridSearchCV(model, param_grid = grid_values,scoring = 'recall')\n",
    "grid_clf_acc.fit(X_train, y_train)\n",
    "\n",
    "# Predict values based on new parameters\n",
    "y_pred_acc = grid_clf_acc.predict(X_test)\n",
    "\n",
    "# New Model Evaluation metrics\n",
    "# print('Accuracy Score : ' + str(accuracy_score(y_test, y_pred_acc)))\n",
    "# print('Precision Score : ' + str(precision_score(y_test, y_pred_acc)))\n",
    "# print('Recall Score : ' + str(recall_score(y_test, y_pred_acc)))\n",
    "# print('F1 Score : ' + str(f1_score(y_test, y_pred_acc)))\n",
    "\n",
    "# Logistic Regression (Grid Search) Confusion matrix\n",
    "confusion_matrix(y_test, y_pred_acc)\n",
    "\n",
    "print('training score: {}'.format(model.score(X_train, y_train)))\n",
    "print(' testing score: {}'.format(model.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "undefined.--profile=pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
