{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recreating an example to gain understanding for KMeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37373737373737376\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, plot_confusion_matrix, recall_score\n",
    "%matplotlib inline\n",
    "\n",
    "train_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/train.csv\"\n",
    "train = pd.read_csv(train_url)\n",
    "test_url = \"http://s3.amazonaws.com/assets.datacamp.com/course/Kaggle/test.csv\"\n",
    "test = pd.read_csv(test_url)\n",
    "\n",
    "# print(\"***** Train_Set *****\")\n",
    "# print(train.head())\n",
    "# print(\"\\n\")\n",
    "# print(\"***** Test_Set *****\")\n",
    "# print(test.head())\n",
    "\n",
    "# print(\"***** Train_Set *****\")\n",
    "# print(train.describe())\n",
    "# print(\"\\n\")\n",
    "# print(\"***** Test_Set *****\")\n",
    "# print(test.describe())\n",
    "\n",
    "# print(train.columns.values)\n",
    "train.isna().head()\n",
    "test.isna().head()\n",
    "\n",
    "# print(\"***** In the train set *****\")\n",
    "# print(train.isna().sum())\n",
    "# print(\"\\n\")\n",
    "# print(\"***** In the test set *****\")\n",
    "# print(test.isna().sum())\n",
    "\n",
    "train.fillna(train.mean(), inplace=True)\n",
    "test.fillna(test.mean(), inplace=True)\n",
    "\n",
    "# print(train.isna().sum())\n",
    "# print(test.isna().sum())\n",
    "\n",
    "train['Ticket'].head()\n",
    "train['Cabin'].head()\n",
    "train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n",
    "\n",
    "# g = sns.FacetGrid(train, col='Survived')\n",
    "# g.map(plt.hist, 'Age', bins=20)\n",
    "\n",
    "# grid = sns.FacetGrid(train, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "# grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "# grid.add_legend(); \n",
    "\n",
    "# train.info()\n",
    "\n",
    "train = train.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "test = test.drop(['Name', 'Ticket', 'Cabin', 'Embarked'], axis=1)\n",
    "\n",
    "labelEncoder = LabelEncoder()\n",
    "labelEncoder.fit(train['Sex'])\n",
    "labelEncoder.fit(test['Sex'])\n",
    "train['Sex'] = labelEncoder.transform(train['Sex'])\n",
    "test['Sex'] = labelEncoder.transform(test['Sex'])\n",
    "\n",
    "# train.info()\n",
    "\n",
    "# test.info()\n",
    "\n",
    "X = np.array(train.drop(['Survived'], 1).astype(float))\n",
    "y = np.array(train['Survived'])\n",
    "# train.info()\n",
    "\n",
    "\n",
    "# K-Means Model \n",
    "\n",
    "kmeans = KMeans(n_clusters=2, max_iter=600, algorithm='auto')\n",
    "kmeans.fit(X)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "correct = 0\n",
    "for i in range(len(X)):\n",
    "    predict_me = np.array(X[i].astype(float))\n",
    "    predict_me = predict_me.reshape(-1, len(predict_me))\n",
    "    prediction = kmeans.predict(predict_me)\n",
    "    if prediction[0] == y[i]:\n",
    "        correct += 1\n",
    "\n",
    "print(correct/len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting with KMeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Leeftijd  MQ_category  Length_cm  Weight    BMI\n",
      "0     0.0      4.55          3.0      111.5    19.8  15.93\n",
      "5     0.0      5.86          4.0      114.5    19.9  15.18\n",
      "6     0.0      5.83          4.0      115.1    22.7  17.13\n",
      "8     1.0      4.43          3.0      115.9    22.3  16.60\n",
      "9     0.0      5.67          2.0      109.7    15.9  13.21\n",
      "Score for training: -23655.384736118136\n",
      "Score for testing: -96327698.19398567\n",
      "[[ 0  0  0  0  0  0]\n",
      " [16  0  9  0  0  0]\n",
      " [21  0 18  0  0  0]\n",
      " [77  1 67  0  0  0]\n",
      " [33  0 29  0  0  0]\n",
      " [26  0 11  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# predicting with KMeans model with validation set\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans \n",
    "\n",
    "# reading data file:\n",
    "data_dataframe = pd.read_csv('../TOCOM.csv', sep=';') \n",
    "\n",
    "# dropping NaN values: \n",
    "data_dataframe.dropna(subset = [\"Gender\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"Leeftijd\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"AST\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"Length_cm\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"Weight\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"BMI\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"MQ\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"MQ_category\"], inplace=True)\n",
    "\n",
    "# dropping colums:\n",
    "data_dataframe_modified = data_dataframe.drop(data_dataframe.columns[[0, 2, 3, 4, 6, 7, 9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22,23,24,25,26,27,28,29,30,31,32,33,34, 35, 36]], axis=1)\n",
    "\n",
    "# printing head of the dataframe: \n",
    "print(data_dataframe_modified.head())\n",
    "\n",
    "# setting X and y: \n",
    "X = data_dataframe_modified.iloc[:, :-1].values\n",
    "y = data_dataframe_modified[\"MQ_category\"].values\n",
    "\n",
    "# splitting dataframe in train, test and validation sets:\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2 ,random_state=11111 , stratify = y) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=11111)\n",
    "\n",
    "# KMeans model: \n",
    "kmeans_model = KMeans(n_clusters=3, max_iter=6)\n",
    "\n",
    "# using KMeans model classifier in order to fit the data:\n",
    "kmeans_model.fit(X_train, y_train)\n",
    "\n",
    "# predicting y-data with classifier:\n",
    "y_predict = kmeans_model.predict(X_test)\n",
    "\n",
    "# getting the scores for the X_test and y_test subsets:\n",
    "kmeans_model.score(X_test, y_test)\n",
    "\n",
    "# printing the scores:\n",
    "print('Score for training: {}'.format(kmeans_model.score(X_train, y_train)))\n",
    "print('Score for testing: {}'.format(kmeans_model.score(X_test, y_test)))\n",
    "\n",
    "# Printing the confusion matrix:\n",
    "confusionMatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confusionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Gender  Leeftijd  MQ_category  Length_cm  Weight    BMI\n",
      "0     0.0      4.55          3.0      111.5    19.8  15.93\n",
      "1     1.0      5.01          NaN      112.5    17.3  13.67\n",
      "2     0.0      5.28          NaN      110.9    21.0  17.07\n",
      "3     0.0      5.79          NaN      105.7    18.2  16.29\n",
      "4     1.0      4.73          NaN      116.0    22.4  16.65\n",
      "Score of testing: -1.4390655593080706\n",
      "[[ 0  0  0  0  0  0]\n",
      " [ 8 15  2  0  0  0]\n",
      " [11 18 11  0  0  0]\n",
      " [35 90 51  0  0  0]\n",
      " [17 20 26  0  0  0]\n",
      " [ 6 21 11  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# With scaling \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# reading data file:\n",
    "data_dataframe = pd.read_csv('../TOCOM.csv', sep=';') \n",
    "\n",
    "# dropping colums:\n",
    "data_dataframe_modified = data_dataframe.drop(data_dataframe.columns[[0, 2, 3, 4, 6, 7, 9, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22,23,24,25,26,27,28,29,30,31,32,33,34, 35, 36]], axis=1)\n",
    "\n",
    "# dropping NaN values: \n",
    "data_dataframe.dropna(subset = [\"Gender\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"Leeftijd\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"AST\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"Length_cm\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"Weight\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"BMI\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"MQ\"], inplace=True)\n",
    "data_dataframe.dropna(subset = [\"MQ_category\"], inplace=True)\n",
    "\n",
    "# calculating the median of the dataframe: \n",
    "data = data_dataframe_modified.fillna(data_dataframe_modified.median())\n",
    "\n",
    "# printing head of the dataframe: \n",
    "print(data_dataframe_modified.head())\n",
    "\n",
    "# setting a variable data:\n",
    "N = 2\n",
    "data = data.iloc[:, :-N]\n",
    "\n",
    "# setting y variable: \n",
    "y = data[\"MQ_category\"].values.astype(int)\n",
    "\n",
    "# scaling the data:\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(data), columns=data.columns)\n",
    "scaled_data\n",
    "\n",
    "# setting X variable: \n",
    "X = scaled_data.drop(scaled_data.columns[[2]], axis= 1)\n",
    "\n",
    "# splitting dataframe in train, test and validation sets:\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size = 0.2, random_state = 11111, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size= 0.25, random_state = 11111)\n",
    "\n",
    "# KMeans model: \n",
    "kMeans_model = KMeans(n_clusters = 3, init = 'k-means++', n_init = 10, max_iter = 100)\n",
    "\n",
    "# using KMeans model classifier in order to fit the data:\n",
    "kMeans_model.fit(X_train, y_train)\n",
    "\n",
    "# predicting y-data with classifier:\n",
    "y_predict = kMeans_model.predict(X_test)\n",
    "\n",
    "# getting the scores for the X_test and y_test subsets:\n",
    "testing_score = kMeans_model.score(X_test, y_test)\n",
    "print(f\"Score of testing: {testing_score}\")\n",
    "\n",
    "# Printing the confusion matrix:\n",
    "confusionMatrix = confusion_matrix(y_test, y_predict)\n",
    "print(confusionMatrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark",
   "language": "python",
   "name": "undefined.--profile=pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
